{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highlights of the scikit-learn release 0.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching dataframe from OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the attribute `as_frame` in complement of `return_X_y=True` to get directly the data as a dataframe and a serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y = fetch_openml('adult', version=2, as_frame=True, return_X_y=True)\n",
    "df = df.drop(columns=['fnlwgt', 'education-num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New histogram-based gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y = fetch_openml('titanic', version=1, as_frame=True, return_X_y=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier().fit(df[['fare']], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = HistGradientBoostingClassifier().fit(df[['fare']], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['age', 'fare']\n",
    "numeric_transformer = FunctionTransformer()\n",
    "\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OrdinalEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', HistGradientBoostingClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoother integration of Dataframe in partial dependece plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "cal_housing = fetch_california_housing()\n",
    "X = pd.DataFrame(cal_housing.data, columns=cal_housing.feature_names)\n",
    "y = cal_housing.target\n",
    "\n",
    "y -= y.mean()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "est = make_pipeline(QuantileTransformer(),\n",
    "                    MLPRegressor(hidden_layer_sizes=(50, 50),\n",
    "                                 learning_rate_init=0.01,\n",
    "                                 early_stopping=True))\n",
    "est.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = ['MedInc', 'AveOccup', 'HouseAge', 'AveRooms']\n",
    "plot_partial_dependence(est, X_train, features,\n",
    "                        n_jobs=-1, grid_resolution=20)\n",
    "fig = plt.gcf()\n",
    "fig.suptitle('Partial dependence of house value on non-location features\\n'\n",
    "             'for the California housing dataset, with MLPRegressor')\n",
    "fig.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Imputers and option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y = fetch_openml('titanic', version=1, as_frame=True, return_X_y=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['boat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "SimpleImputer(\n",
    "    missing_values=None, strategy='constant',\n",
    "    fill_value='0', add_indicator=True\n",
    ").fit_transform(df[['boat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer, IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calhousing = fetch_california_housing()\n",
    "\n",
    "X = pd.DataFrame(calhousing.data, columns=calhousing.feature_names)\n",
    "y = pd.Series(calhousing.target, name='house_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "density = 4  # one in 10 values will be NaN\n",
    "\n",
    "mask = rng.randint(density, size=X.shape) == 0\n",
    "X_na = X.copy()\n",
    "X_na.values[mask] = np.nan\n",
    "X_na.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_na, X_test_na, y_train_na, y_test_na = train_test_split(\n",
    "    X_na[y<4.9], y[y<4.9], test_size=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SimpleImputer(strategy=\"mean\", add_indicator=True),\n",
    "    LinearRegression()\n",
    ")\n",
    "model.fit(X_train_na, y_train_na).score(X_test_na, y_test_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    IterativeImputer(add_indicator=True),\n",
    "    LinearRegression()\n",
    ")\n",
    "model.fit(X_train_na, y_train_na).score(X_test_na, y_test_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNNImputer(add_indicator=True),\n",
    "    LinearRegression()\n",
    ")\n",
    "model.fit(X_train_na, y_train_na).score(X_test_na, y_test_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_results(ax, y_true, y_pred, title, scores, elapsed_time):\n",
    "    \"\"\"Scatter plot of the predicted vs true targets.\"\"\"\n",
    "    ax.plot([y_true.min(), y_true.max()],\n",
    "            [y_true.min(), y_true.max()],\n",
    "            '--r', linewidth=2)\n",
    "    ax.scatter(y_true, y_pred, alpha=0.2)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    ax.spines['bottom'].set_position(('outward', 10))\n",
    "    ax.set_xlim([y_true.min(), y_true.max()])\n",
    "    ax.set_ylim([y_true.min(), y_true.max()])\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    extra = plt.Rectangle((0, 0), 0, 0, fc=\"w\", fill=False,\n",
    "                          edgecolor='none', linewidth=0)\n",
    "    ax.legend([extra], [scores], loc='upper left')\n",
    "    title = title + '\\n Evaluation in {:.2f} seconds'.format(elapsed_time)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "estimators = [\n",
    "    ('Random Forest', RandomForestRegressor(random_state=42)),\n",
    "    ('Lasso', LassoCV()),\n",
    "    ('Gradient Boosting', HistGradientBoostingRegressor(random_state=0))\n",
    "]\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=estimators, final_estimator=RidgeCV()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(9, 7))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for ax, (name, est) in zip(axs, estimators + [('Stacking Regressor',\n",
    "                                               stacking_regressor)]):\n",
    "    start_time = time.time()\n",
    "    score = cross_validate(est, X, y,\n",
    "                           scoring=['r2', 'neg_mean_absolute_error'],\n",
    "                           n_jobs=-1, verbose=0)\n",
    "    elapsed_time = time.time() - time.time()\n",
    "\n",
    "    y_pred = cross_val_predict(est, X, y, n_jobs=-1, verbose=0)\n",
    "    plot_regression_results(\n",
    "        ax, y, y_pred,\n",
    "        name,\n",
    "        (r'$R^2={:.2f} \\pm {:.2f}$' + '\\n' + r'$MAE={:.2f} \\pm {:.2f}$')\n",
    "        .format(np.mean(score['test_r2']),\n",
    "                np.std(score['test_r2']),\n",
    "                -np.mean(score['test_neg_mean_absolute_error']),\n",
    "                np.std(score['test_neg_mean_absolute_error'])),\n",
    "        elapsed_time)\n",
    "\n",
    "plt.suptitle('Single predictors versus stacked predictors')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance computed via permuation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(random_state=0, n_features=5, n_informative=3)\n",
    "rf = RandomForestClassifier(random_state=0).fit(X, y)\n",
    "result = permutation_importance(rf, X, y, n_repeats=10, random_state=0,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=range(X.shape[1]))\n",
    "ax.set_title(\"Permutation Importance of each feature\")\n",
    "ax.set_ylabel(\"Features\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0, ccp_alpha=0).fit(X, y)\n",
    "print(\"Average number of nodes without pruning {:.1f}\".format(\n",
    "    np.mean([e.tree_.node_count for e in rf.estimators_])))\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, ccp_alpha=0.05).fit(X, y)\n",
    "print(\"Average number of nodes with pruning {:.1f}\".format(\n",
    "    np.mean([e.tree_.node_count for e in rf.estimators_])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
